{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### All Again"
      ],
      "metadata": {
        "id": "GtOlkiUV149N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install -U openai-whisper\n",
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "!pip install ffmpeg-python\n",
        "\n",
        "# Install FFmpeg (if not already installed in Colab)\n",
        "!apt-get install ffmpeg\n",
        "\n",
        "# Install other necessary packages\n",
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFPKXj52156O",
        "outputId": "d69fdccf-1e8e-4b9f-af65-2fbf1a0a6aac"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20240930)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.6)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.8.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu117\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import whisper\n",
        "import nltk\n",
        "import ffmpeg\n",
        "import subprocess\n",
        "import re\n",
        "from google.colab import files\n",
        "from IPython.display import Video, display\n",
        "\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SABxZMXA16ft",
        "outputId": "171d6ef1-7ad2-48d8-a728-b2a9fdd8a809"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Is GPU available:\", torch.cuda.is_available())\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SjMOpsa2AP7",
        "outputId": "9e4393b6-6a4d-4f02-86a4-7e37f20d50d9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is GPU available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_filename = list(uploaded.keys())[0]\n",
        "print(f\"Uploaded video file: {video_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_i36CZW2HVi",
        "outputId": "479baad5-d253-492a-8edc-bd71f8473bb1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded video file: How do SSDs Work_ How to fit 3 WEEKS of TV in a microchip the size of a dime!! Explained in 3min..mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract audio from the video using FFmpeg\n",
        "audio_filename = \"extracted_audio.wav\"\n",
        "\n",
        "command = [\n",
        "    'ffmpeg',\n",
        "    '-i', video_filename,\n",
        "    '-f', 'wav',\n",
        "    '-ar', '16000',  # Sample rate\n",
        "    '-ac', '1',      # Mono channel\n",
        "    audio_filename\n",
        "]\n",
        "\n",
        "subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
        "print(f\"Audio extracted and saved as {audio_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ur446xx2OhE",
        "outputId": "8e5906de-7f36-4584-d298-987c4bba7b9a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio extracted and saved as extracted_audio.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Whisper model\n",
        "model = whisper.load_model(\"base\", device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3UJdwiM2S_t",
        "outputId": "dd001e21-542d-49b5-fc6b-8cdf13c12fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 139M/139M [00:00<00:00, 149MiB/s]\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transcribe the audio with timestamps\n",
        "print(\"Starting transcription...\")\n",
        "result = model.transcribe(audio_filename, word_timestamps=True)\n",
        "print(\"Transcription completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is4cJUqV2V92",
        "outputId": "67a376f7-644c-4e94-eb76-a446a418a1cd"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting transcription...\n",
            "Transcription completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "id": "P0SxncBW2Zp-",
        "outputId": "17ecb4f4-8538-44ca-8a71-6c925b8f7b2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': \" Most smartphones can store 128GB and this solid-state drive can store one terabyte of data and it all happens inside this microchip right here. If this one terabyte solid-state drive were full of movies and TV shows it would take about three weeks of non-stop binging to watch them all. So how can this incredibly small microchip fit such an insane amount of content? To understand that we've got to zoom into a nanoscopic view of the insides. In here we can see an individual memory cell called charge trap flash. This memory cell stores three bits of information by trapping different levels of electrons on a charge trap. Very few extra electrons are a 1 1 1 while a lot of electrons are a 0 0 0 and the other levels of trapped electrons have other three bit designations. Measuring this value doesn't change the amount of electrons and once electrons are placed on the charge trap they stay trapped there for years. However when the memory cell is erased the electrons are forcibly removed. To reach a terabyte of storage capacity in a single chip this memory cell is copied and it's copied a lot. First these memory cells are stacked 100 layers tall and then these stacks of cells are copied 40,000 columns across which is then copied 50,000 rows down. You can kind of think of it as a 3d Excel spreadsheet where the values can only be 0 to 7 and this spreadsheet has 40,000 columns by 50,000 rows and then there are 100 different spreadsheets stacked in layers one on top of another. In order to isolate and determine which row and layer to write to or read from control gate selectors are used along layers and bit line selectors are used along the rows. We're going to zoom out to the view that we had earlier where we can see the overall microchip. Here's the 3d array of charge trap flash cells and control gates that we were just looking at. This is a massive layout of memory cells but engineers didn't stop there. In order to fit more capacity they copied this layout onto the other side and then copied it eight times again and crammed it all into a single microchip and that's it. Three weeks of non-stop binging movies and TV squeezed into a microchip the size of a dime. Watch our follow up episode to get a complete and in-depth understanding as to how everything that I just talked about works. Thanks.\", 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 7.14, 'text': ' Most smartphones can store 128GB and this solid-state drive can store one', 'tokens': [50364, 4534, 26782, 393, 3531, 29810, 8769, 293, 341, 5100, 12, 15406, 3332, 393, 3531, 472, 50719], 'temperature': 0.0, 'avg_logprob': -0.16148338317871094, 'compression_ratio': 1.6144067796610169, 'no_speech_prob': 0.07145284116268158, 'words': [{'word': ' Most', 'start': 0.0, 'end': 0.84, 'probability': 0.8759965896606445}, {'word': ' smartphones', 'start': 0.84, 'end': 1.54, 'probability': 0.8695709109306335}, {'word': ' can', 'start': 1.54, 'end': 1.96, 'probability': 0.9774282574653625}, {'word': ' store', 'start': 1.96, 'end': 2.28, 'probability': 0.993000864982605}, {'word': ' 128GB', 'start': 2.28, 'end': 3.98, 'probability': 0.7298099845647812}, {'word': ' and', 'start': 3.98, 'end': 4.8, 'probability': 0.5080980658531189}, {'word': ' this', 'start': 4.8, 'end': 5.0, 'probability': 0.9722431302070618}, {'word': ' solid', 'start': 5.0, 'end': 5.36, 'probability': 0.8007243871688843}, {'word': '-state', 'start': 5.36, 'end': 5.7, 'probability': 0.806786060333252}, {'word': ' drive', 'start': 5.7, 'end': 6.08, 'probability': 0.9474733471870422}, {'word': ' can', 'start': 6.08, 'end': 6.36, 'probability': 0.988676905632019}, {'word': ' store', 'start': 6.36, 'end': 6.76, 'probability': 0.9933491349220276}, {'word': ' one', 'start': 6.76, 'end': 7.14, 'probability': 0.7997901439666748}]}, {'id': 1, 'seek': 0, 'start': 7.14, 'end': 13.3, 'text': ' terabyte of data and it all happens inside this microchip right here. If this', 'tokens': [50719, 1796, 34529, 295, 1412, 293, 309, 439, 2314, 1854, 341, 4532, 339, 647, 558, 510, 13, 759, 341, 51030], 'temperature': 0.0, 'avg_logprob': -0.16148338317871094, 'compression_ratio': 1.6144067796610169, 'no_speech_prob': 0.07145284116268158, 'words': [{'word': ' terabyte', 'start': 7.14, 'end': 7.8, 'probability': 0.954651951789856}, {'word': ' of', 'start': 7.8, 'end': 8.08, 'probability': 0.9872473478317261}, {'word': ' data', 'start': 8.08, 'end': 8.42, 'probability': 0.9960891008377075}, {'word': ' and', 'start': 8.42, 'end': 8.84, 'probability': 0.4862697422504425}, {'word': ' it', 'start': 8.84, 'end': 8.96, 'probability': 0.9648112058639526}, {'word': ' all', 'start': 8.96, 'end': 9.26, 'probability': 0.9895620942115784}, {'word': ' happens', 'start': 9.26, 'end': 9.74, 'probability': 0.9932658672332764}, {'word': ' inside', 'start': 9.74, 'end': 10.54, 'probability': 0.9937267303466797}, {'word': ' this', 'start': 10.54, 'end': 10.92, 'probability': 0.943041205406189}, {'word': ' microchip', 'start': 10.92, 'end': 11.6, 'probability': 0.9309370915095011}, {'word': ' right', 'start': 11.6, 'end': 12.24, 'probability': 0.8660473227500916}, {'word': ' here.', 'start': 12.24, 'end': 12.6, 'probability': 0.9963755011558533}, {'word': ' If', 'start': 12.9, 'end': 13.02, 'probability': 0.983034610748291}, {'word': ' this', 'start': 13.02, 'end': 13.3, 'probability': 0.9934589266777039}]}, {'id': 2, 'seek': 0, 'start': 13.3, 'end': 18.42, 'text': ' one terabyte solid-state drive were full of movies and TV shows it would take', 'tokens': [51030, 472, 1796, 34529, 5100, 12, 15406, 3332, 645, 1577, 295, 6233, 293, 3558, 3110, 309, 576, 747, 51287], 'temperature': 0.0, 'avg_logprob': -0.16148338317871094, 'compression_ratio': 1.6144067796610169, 'no_speech_prob': 0.07145284116268158, 'words': [{'word': ' one', 'start': 13.3, 'end': 13.7, 'probability': 0.9503807425498962}, {'word': ' terabyte', 'start': 13.7, 'end': 14.28, 'probability': 0.9813205301761627}, {'word': ' solid', 'start': 14.28, 'end': 14.72, 'probability': 0.9147976040840149}, {'word': '-state', 'start': 14.72, 'end': 15.08, 'probability': 0.9565818011760712}, {'word': ' drive', 'start': 15.08, 'end': 15.52, 'probability': 0.9934244155883789}, {'word': ' were', 'start': 15.52, 'end': 15.78, 'probability': 0.9902024269104004}, {'word': ' full', 'start': 15.78, 'end': 16.08, 'probability': 0.9958641529083252}, {'word': ' of', 'start': 16.08, 'end': 16.28, 'probability': 0.9948282837867737}, {'word': ' movies', 'start': 16.28, 'end': 16.62, 'probability': 0.9937036633491516}, {'word': ' and', 'start': 16.62, 'end': 16.9, 'probability': 0.9893755912780762}, {'word': ' TV', 'start': 16.9, 'end': 17.22, 'probability': 0.9242462515830994}, {'word': ' shows', 'start': 17.22, 'end': 17.72, 'probability': 0.9870135188102722}, {'word': ' it', 'start': 17.72, 'end': 18.08, 'probability': 0.27880242466926575}, {'word': ' would', 'start': 18.08, 'end': 18.24, 'probability': 0.9896578192710876}, {'word': ' take', 'start': 18.24, 'end': 18.42, 'probability': 0.9929203391075134}]}, {'id': 3, 'seek': 0, 'start': 18.42, 'end': 23.34, 'text': ' about three weeks of non-stop binging to watch them all. So how can this', 'tokens': [51287, 466, 1045, 3259, 295, 2107, 12, 13559, 272, 8716, 281, 1159, 552, 439, 13, 407, 577, 393, 341, 51528], 'temperature': 0.0, 'avg_logprob': -0.16148338317871094, 'compression_ratio': 1.6144067796610169, 'no_speech_prob': 0.07145284116268158, 'words': [{'word': ' about', 'start': 18.42, 'end': 18.74, 'probability': 0.9861444234848022}, {'word': ' three', 'start': 18.74, 'end': 19.14, 'probability': 0.5826193690299988}, {'word': ' weeks', 'start': 19.14, 'end': 19.6, 'probability': 0.9978213310241699}, {'word': ' of', 'start': 19.6, 'end': 19.8, 'probability': 0.9920291900634766}, {'word': ' non', 'start': 19.8, 'end': 20.14, 'probability': 0.9927273988723755}, {'word': '-stop', 'start': 20.14, 'end': 20.6, 'probability': 0.8726144134998322}, {'word': ' binging', 'start': 20.6, 'end': 21.06, 'probability': 0.8346368670463562}, {'word': ' to', 'start': 21.06, 'end': 21.38, 'probability': 0.9965043067932129}, {'word': ' watch', 'start': 21.38, 'end': 21.7, 'probability': 0.9971150159835815}, {'word': ' them', 'start': 21.7, 'end': 21.92, 'probability': 0.9707321524620056}, {'word': ' all.', 'start': 21.92, 'end': 22.1, 'probability': 0.9898858070373535}, {'word': ' So', 'start': 22.46, 'end': 22.66, 'probability': 0.9842199683189392}, {'word': ' how', 'start': 22.66, 'end': 22.92, 'probability': 0.9195020198822021}, {'word': ' can', 'start': 22.92, 'end': 23.12, 'probability': 0.990998387336731}, {'word': ' this', 'start': 23.12, 'end': 23.34, 'probability': 0.9968656897544861}]}, {'id': 4, 'seek': 0, 'start': 23.34, 'end': 29.24, 'text': ' incredibly small microchip fit such an insane amount of content? To understand', 'tokens': [51528, 6252, 1359, 4532, 339, 647, 3318, 1270, 364, 10838, 2372, 295, 2701, 30, 1407, 1223, 51830], 'temperature': 0.0, 'avg_logprob': -0.16148338317871094, 'compression_ratio': 1.6144067796610169, 'no_speech_prob': 0.07145284116268158, 'words': [{'word': ' incredibly', 'start': 23.34, 'end': 24.06, 'probability': 0.9909018278121948}, {'word': ' small', 'start': 24.06, 'end': 24.54, 'probability': 0.9981040954589844}, {'word': ' microchip', 'start': 24.54, 'end': 25.38, 'probability': 0.9952471057573954}, {'word': ' fit', 'start': 25.38, 'end': 25.72, 'probability': 0.9805780649185181}, {'word': ' such', 'start': 25.72, 'end': 26.22, 'probability': 0.9921976923942566}, {'word': ' an', 'start': 26.22, 'end': 26.44, 'probability': 0.9945441484451294}, {'word': ' insane', 'start': 26.44, 'end': 27.02, 'probability': 0.9975676536560059}, {'word': ' amount', 'start': 27.02, 'end': 27.4, 'probability': 0.9980952143669128}, {'word': ' of', 'start': 27.4, 'end': 27.66, 'probability': 0.9987743496894836}, {'word': ' content?', 'start': 27.66, 'end': 28.12, 'probability': 0.9970445036888123}, {'word': ' To', 'start': 28.56, 'end': 28.7, 'probability': 0.9859748482704163}, {'word': ' understand', 'start': 28.7, 'end': 29.24, 'probability': 0.9979750514030457}]}, {'id': 5, 'seek': 2924, 'start': 29.24, 'end': 35.54, 'text': \" that we've got to zoom into a nanoscopic view of the insides. In here we can\", 'tokens': [50364, 300, 321, 600, 658, 281, 8863, 666, 257, 14067, 10466, 40216, 1910, 295, 264, 1028, 1875, 13, 682, 510, 321, 393, 50680], 'temperature': 0.0, 'avg_logprob': -0.23158013820648193, 'compression_ratio': 1.7623318385650224, 'no_speech_prob': 0.04269111156463623, 'words': [{'word': ' that', 'start': 29.24, 'end': 29.56, 'probability': 0.2502625584602356}, {'word': \" we've\", 'start': 29.56, 'end': 30.12, 'probability': 0.6870019286870956}, {'word': ' got', 'start': 30.12, 'end': 30.26, 'probability': 0.9654553532600403}, {'word': ' to', 'start': 30.26, 'end': 30.4, 'probability': 0.871936023235321}, {'word': ' zoom', 'start': 30.4, 'end': 30.62, 'probability': 0.9965667724609375}, {'word': ' into', 'start': 30.62, 'end': 31.02, 'probability': 0.5580240488052368}, {'word': ' a', 'start': 31.02, 'end': 31.18, 'probability': 0.557076096534729}, {'word': ' nanoscopic', 'start': 31.18, 'end': 31.94, 'probability': 0.833984394868215}, {'word': ' view', 'start': 31.94, 'end': 32.22, 'probability': 0.9970941543579102}, {'word': ' of', 'start': 32.22, 'end': 32.44, 'probability': 0.9950199127197266}, {'word': ' the', 'start': 32.44, 'end': 32.56, 'probability': 0.9982978701591492}, {'word': ' insides.', 'start': 32.56, 'end': 33.24, 'probability': 0.8186113238334656}, {'word': ' In', 'start': 33.88, 'end': 34.56, 'probability': 0.9804152250289917}, {'word': ' here', 'start': 34.56, 'end': 34.84, 'probability': 0.9939508438110352}, {'word': ' we', 'start': 34.84, 'end': 35.38, 'probability': 0.3904789090156555}, {'word': ' can', 'start': 35.38, 'end': 35.54, 'probability': 0.9948980212211609}]}, {'id': 6, 'seek': 2924, 'start': 35.54, 'end': 40.98, 'text': ' see an individual memory cell called charge trap flash. This memory cell stores', 'tokens': [50680, 536, 364, 2609, 4675, 2815, 1219, 4602, 11487, 7319, 13, 639, 4675, 2815, 9512, 50951], 'temperature': 0.0, 'avg_logprob': -0.23158013820648193, 'compression_ratio': 1.7623318385650224, 'no_speech_prob': 0.04269111156463623, 'words': [{'word': ' see', 'start': 35.54, 'end': 35.76, 'probability': 0.9981718063354492}, {'word': ' an', 'start': 35.76, 'end': 35.94, 'probability': 0.9860230684280396}, {'word': ' individual', 'start': 35.94, 'end': 36.52, 'probability': 0.9954076409339905}, {'word': ' memory', 'start': 36.52, 'end': 36.96, 'probability': 0.980967104434967}, {'word': ' cell', 'start': 36.96, 'end': 37.36, 'probability': 0.9967641830444336}, {'word': ' called', 'start': 37.36, 'end': 37.76, 'probability': 0.9662535190582275}, {'word': ' charge', 'start': 37.76, 'end': 38.36, 'probability': 0.7846405506134033}, {'word': ' trap', 'start': 38.36, 'end': 38.62, 'probability': 0.4448215365409851}, {'word': ' flash.', 'start': 38.62, 'end': 39.08, 'probability': 0.8594878315925598}, {'word': ' This', 'start': 39.6, 'end': 39.82, 'probability': 0.994452178478241}, {'word': ' memory', 'start': 39.82, 'end': 40.18, 'probability': 0.9971543550491333}, {'word': ' cell', 'start': 40.18, 'end': 40.52, 'probability': 0.9820444583892822}, {'word': ' stores', 'start': 40.52, 'end': 40.98, 'probability': 0.9886259436607361}]}, {'id': 7, 'seek': 2924, 'start': 40.98, 'end': 45.08, 'text': ' three bits of information by trapping different levels of electrons on a charge', 'tokens': [50951, 1045, 9239, 295, 1589, 538, 944, 3759, 819, 4358, 295, 14265, 322, 257, 4602, 51158], 'temperature': 0.0, 'avg_logprob': -0.23158013820648193, 'compression_ratio': 1.7623318385650224, 'no_speech_prob': 0.04269111156463623, 'words': [{'word': ' three', 'start': 40.98, 'end': 41.32, 'probability': 0.7221537828445435}, {'word': ' bits', 'start': 41.32, 'end': 41.52, 'probability': 0.9964894652366638}, {'word': ' of', 'start': 41.52, 'end': 41.72, 'probability': 0.9985857009887695}, {'word': ' information', 'start': 41.72, 'end': 42.22, 'probability': 0.9992942810058594}, {'word': ' by', 'start': 42.22, 'end': 42.58, 'probability': 0.9929242134094238}, {'word': ' trapping', 'start': 42.58, 'end': 42.98, 'probability': 0.9870297014713287}, {'word': ' different', 'start': 42.98, 'end': 43.3, 'probability': 0.9944761395454407}, {'word': ' levels', 'start': 43.3, 'end': 43.68, 'probability': 0.997032880783081}, {'word': ' of', 'start': 43.68, 'end': 43.92, 'probability': 0.9986217021942139}, {'word': ' electrons', 'start': 43.92, 'end': 44.36, 'probability': 0.9983004927635193}, {'word': ' on', 'start': 44.36, 'end': 44.72, 'probability': 0.9975322484970093}, {'word': ' a', 'start': 44.72, 'end': 44.82, 'probability': 0.9934816360473633}, {'word': ' charge', 'start': 44.82, 'end': 45.08, 'probability': 0.9457417130470276}]}, {'id': 8, 'seek': 2924, 'start': 45.08, 'end': 54.1, 'text': ' trap. Very few extra electrons are a 1 1 1 while a lot of electrons are a 0 0 0', 'tokens': [51158, 11487, 13, 4372, 1326, 2857, 14265, 366, 257, 502, 502, 502, 1339, 257, 688, 295, 14265, 366, 257, 1958, 1958, 1958, 51606], 'temperature': 0.0, 'avg_logprob': -0.23158013820648193, 'compression_ratio': 1.7623318385650224, 'no_speech_prob': 0.04269111156463623, 'words': [{'word': ' trap.', 'start': 45.08, 'end': 45.56, 'probability': 0.9824569821357727}, {'word': ' Very', 'start': 45.9, 'end': 46.22, 'probability': 0.9800547361373901}, {'word': ' few', 'start': 46.22, 'end': 46.54, 'probability': 0.9991376399993896}, {'word': ' extra', 'start': 46.54, 'end': 47.04, 'probability': 0.9929423332214355}, {'word': ' electrons', 'start': 47.04, 'end': 47.8, 'probability': 0.9895709753036499}, {'word': ' are', 'start': 47.8, 'end': 48.08, 'probability': 0.9161498546600342}, {'word': ' a', 'start': 48.08, 'end': 48.22, 'probability': 0.8085597157478333}, {'word': ' 1', 'start': 48.22, 'end': 48.56, 'probability': 0.6239793300628662}, {'word': ' 1', 'start': 48.56, 'end': 49.04, 'probability': 0.16321177780628204}, {'word': ' 1', 'start': 49.04, 'end': 49.74, 'probability': 0.9027976393699646}, {'word': ' while', 'start': 49.74, 'end': 50.44, 'probability': 0.38215532898902893}, {'word': ' a', 'start': 50.44, 'end': 50.62, 'probability': 0.9950830936431885}, {'word': ' lot', 'start': 50.62, 'end': 50.86, 'probability': 0.9992573857307434}, {'word': ' of', 'start': 50.86, 'end': 51.0, 'probability': 0.9988558292388916}, {'word': ' electrons', 'start': 51.0, 'end': 51.56, 'probability': 0.9946430921554565}, {'word': ' are', 'start': 51.56, 'end': 52.06, 'probability': 0.9927238821983337}, {'word': ' a', 'start': 52.06, 'end': 52.24, 'probability': 0.7869519591331482}, {'word': ' 0', 'start': 52.24, 'end': 52.56, 'probability': 0.5569014549255371}, {'word': ' 0', 'start': 52.56, 'end': 53.26, 'probability': 0.9746685028076172}, {'word': ' 0', 'start': 53.26, 'end': 54.1, 'probability': 0.9071545600891113}]}, {'id': 9, 'seek': 2924, 'start': 54.1, 'end': 58.34, 'text': ' and the other levels of trapped electrons have other three bit designations.', 'tokens': [51606, 293, 264, 661, 4358, 295, 14994, 14265, 362, 661, 1045, 857, 1715, 763, 13, 51814], 'temperature': 0.0, 'avg_logprob': -0.23158013820648193, 'compression_ratio': 1.7623318385650224, 'no_speech_prob': 0.04269111156463623, 'words': [{'word': ' and', 'start': 54.1, 'end': 54.56, 'probability': 0.5546464920043945}, {'word': ' the', 'start': 54.56, 'end': 54.72, 'probability': 0.9933081865310669}, {'word': ' other', 'start': 54.72, 'end': 54.9, 'probability': 0.9988335967063904}, {'word': ' levels', 'start': 54.9, 'end': 55.26, 'probability': 0.9957767724990845}, {'word': ' of', 'start': 55.26, 'end': 55.42, 'probability': 0.9917984008789062}, {'word': ' trapped', 'start': 55.42, 'end': 55.7, 'probability': 0.8871957659721375}, {'word': ' electrons', 'start': 55.7, 'end': 56.28, 'probability': 0.9945924878120422}, {'word': ' have', 'start': 56.28, 'end': 56.68, 'probability': 0.9966897964477539}, {'word': ' other', 'start': 56.68, 'end': 56.92, 'probability': 0.98634272813797}, {'word': ' three', 'start': 56.92, 'end': 57.2, 'probability': 0.8676860332489014}, {'word': ' bit', 'start': 57.2, 'end': 57.4, 'probability': 0.8363141417503357}, {'word': ' designations.', 'start': 57.4, 'end': 58.34, 'probability': 0.9740908145904541}]}, {'id': 10, 'seek': 5834, 'start': 58.34, 'end': 63.12, 'text': \" Measuring this value doesn't change the amount of electrons and once\", 'tokens': [50364, 1923, 296, 1345, 341, 2158, 1177, 380, 1319, 264, 2372, 295, 14265, 293, 1564, 50604], 'temperature': 0.0, 'avg_logprob': -0.17528196970621746, 'compression_ratio': 1.7276785714285714, 'no_speech_prob': 0.0005614650435745716, 'words': [{'word': ' Measuring', 'start': 58.34, 'end': 59.38, 'probability': 0.6768091494838396}, {'word': ' this', 'start': 59.38, 'end': 59.66, 'probability': 0.9879837036132812}, {'word': ' value', 'start': 59.66, 'end': 60.06, 'probability': 0.9933866858482361}, {'word': \" doesn't\", 'start': 60.06, 'end': 60.54, 'probability': 0.985749363899231}, {'word': ' change', 'start': 60.54, 'end': 61.02, 'probability': 0.9964752793312073}, {'word': ' the', 'start': 61.02, 'end': 61.2, 'probability': 0.9969452023506165}, {'word': ' amount', 'start': 61.2, 'end': 61.44, 'probability': 0.9948399662971497}, {'word': ' of', 'start': 61.44, 'end': 61.68, 'probability': 0.9969971179962158}, {'word': ' electrons', 'start': 61.68, 'end': 62.12, 'probability': 0.9954008460044861}, {'word': ' and', 'start': 62.12, 'end': 62.78, 'probability': 0.3284239172935486}, {'word': ' once', 'start': 62.78, 'end': 63.12, 'probability': 0.9756146669387817}]}, {'id': 11, 'seek': 5834, 'start': 63.12, 'end': 68.96, 'text': ' electrons are placed on the charge trap they stay trapped there for years. However', 'tokens': [50604, 14265, 366, 7074, 322, 264, 4602, 11487, 436, 1754, 14994, 456, 337, 924, 13, 2908, 50898], 'temperature': 0.0, 'avg_logprob': -0.17528196970621746, 'compression_ratio': 1.7276785714285714, 'no_speech_prob': 0.0005614650435745716, 'words': [{'word': ' electrons', 'start': 63.12, 'end': 63.66, 'probability': 0.9915930032730103}, {'word': ' are', 'start': 63.66, 'end': 63.96, 'probability': 0.99834144115448}, {'word': ' placed', 'start': 63.96, 'end': 64.3, 'probability': 0.9985318183898926}, {'word': ' on', 'start': 64.3, 'end': 64.74, 'probability': 0.9954967498779297}, {'word': ' the', 'start': 64.74, 'end': 64.92, 'probability': 0.9854223728179932}, {'word': ' charge', 'start': 64.92, 'end': 65.32, 'probability': 0.9674826860427856}, {'word': ' trap', 'start': 65.32, 'end': 65.56, 'probability': 0.7331849932670593}, {'word': ' they', 'start': 65.56, 'end': 66.08, 'probability': 0.4251597225666046}, {'word': ' stay', 'start': 66.08, 'end': 66.42, 'probability': 0.9902006983757019}, {'word': ' trapped', 'start': 66.42, 'end': 66.96, 'probability': 0.9666392803192139}, {'word': ' there', 'start': 66.96, 'end': 67.22, 'probability': 0.9682579040527344}, {'word': ' for', 'start': 67.22, 'end': 67.64, 'probability': 0.9855712652206421}, {'word': ' years.', 'start': 67.64, 'end': 68.12, 'probability': 0.9960960745811462}, {'word': ' However', 'start': 68.62, 'end': 68.96, 'probability': 0.9884147644042969}]}, {'id': 12, 'seek': 5834, 'start': 68.96, 'end': 74.66, 'text': ' when the memory cell is erased the electrons are forcibly removed. To reach a', 'tokens': [50898, 562, 264, 4675, 2815, 307, 38359, 264, 14265, 366, 337, 537, 25021, 7261, 13, 1407, 2524, 257, 51176], 'temperature': 0.0, 'avg_logprob': -0.17528196970621746, 'compression_ratio': 1.7276785714285714, 'no_speech_prob': 0.0005614650435745716, 'words': [{'word': ' when', 'start': 68.96, 'end': 69.26, 'probability': 0.30484914779663086}, {'word': ' the', 'start': 69.26, 'end': 69.42, 'probability': 0.9884408712387085}, {'word': ' memory', 'start': 69.42, 'end': 69.68, 'probability': 0.9903443455696106}, {'word': ' cell', 'start': 69.68, 'end': 70.04, 'probability': 0.991165816783905}, {'word': ' is', 'start': 70.04, 'end': 70.3, 'probability': 0.9973933696746826}, {'word': ' erased', 'start': 70.3, 'end': 70.62, 'probability': 0.9814984202384949}, {'word': ' the', 'start': 70.62, 'end': 71.24, 'probability': 0.7258055806159973}, {'word': ' electrons', 'start': 71.24, 'end': 71.78, 'probability': 0.9978116154670715}, {'word': ' are', 'start': 71.78, 'end': 72.2, 'probability': 0.9989373087882996}, {'word': ' forcibly', 'start': 72.2, 'end': 72.88, 'probability': 0.9219948450724283}, {'word': ' removed.', 'start': 72.88, 'end': 73.5, 'probability': 0.997512936592102}, {'word': ' To', 'start': 74.02, 'end': 74.12, 'probability': 0.9787694215774536}, {'word': ' reach', 'start': 74.12, 'end': 74.36, 'probability': 0.9987897276878357}, {'word': ' a', 'start': 74.36, 'end': 74.66, 'probability': 0.9912644624710083}]}, {'id': 13, 'seek': 5834, 'start': 74.66, 'end': 80.6, 'text': ' terabyte of storage capacity in a single chip this memory cell is copied and', 'tokens': [51176, 1796, 34529, 295, 6725, 6042, 294, 257, 2167, 11409, 341, 4675, 2815, 307, 25365, 293, 51458], 'temperature': 0.0, 'avg_logprob': -0.17528196970621746, 'compression_ratio': 1.7276785714285714, 'no_speech_prob': 0.0005614650435745716, 'words': [{'word': ' terabyte', 'start': 74.66, 'end': 75.16, 'probability': 0.9659644663333893}, {'word': ' of', 'start': 75.16, 'end': 75.44, 'probability': 0.9595299363136292}, {'word': ' storage', 'start': 75.44, 'end': 75.84, 'probability': 0.9993188381195068}, {'word': ' capacity', 'start': 75.84, 'end': 76.6, 'probability': 0.9982808828353882}, {'word': ' in', 'start': 76.6, 'end': 76.9, 'probability': 0.9879144430160522}, {'word': ' a', 'start': 76.9, 'end': 77.02, 'probability': 0.9962936043739319}, {'word': ' single', 'start': 77.02, 'end': 77.4, 'probability': 0.9985795021057129}, {'word': ' chip', 'start': 77.4, 'end': 77.92, 'probability': 0.9957730174064636}, {'word': ' this', 'start': 77.92, 'end': 78.4, 'probability': 0.6134465932846069}, {'word': ' memory', 'start': 78.4, 'end': 78.78, 'probability': 0.9919067621231079}, {'word': ' cell', 'start': 78.78, 'end': 79.24, 'probability': 0.994304358959198}, {'word': ' is', 'start': 79.24, 'end': 79.58, 'probability': 0.9987455606460571}, {'word': ' copied', 'start': 79.58, 'end': 79.98, 'probability': 0.9943521022796631}, {'word': ' and', 'start': 79.98, 'end': 80.6, 'probability': 0.7861539125442505}]}, {'id': 14, 'seek': 5834, 'start': 80.6, 'end': 87.3, 'text': \" it's copied a lot. First these memory cells are stacked 100 layers tall and then\", 'tokens': [51458, 309, 311, 25365, 257, 688, 13, 2386, 613, 4675, 5438, 366, 28867, 2319, 7914, 6764, 293, 550, 51812], 'temperature': 0.0, 'avg_logprob': -0.17528196970621746, 'compression_ratio': 1.7276785714285714, 'no_speech_prob': 0.0005614650435745716, 'words': [{'word': \" it's\", 'start': 80.6, 'end': 81.36, 'probability': 0.9351288676261902}, {'word': ' copied', 'start': 81.36, 'end': 81.78, 'probability': 0.988884687423706}, {'word': ' a', 'start': 81.78, 'end': 82.04, 'probability': 0.9782183766365051}, {'word': ' lot.', 'start': 82.04, 'end': 82.4, 'probability': 0.9987446069717407}, {'word': ' First', 'start': 82.88, 'end': 83.1, 'probability': 0.9732478260993958}, {'word': ' these', 'start': 83.1, 'end': 83.72, 'probability': 0.7321901321411133}, {'word': ' memory', 'start': 83.72, 'end': 84.1, 'probability': 0.9881905317306519}, {'word': ' cells', 'start': 84.1, 'end': 84.52, 'probability': 0.9939257502555847}, {'word': ' are', 'start': 84.52, 'end': 84.74, 'probability': 0.9620301127433777}, {'word': ' stacked', 'start': 84.74, 'end': 85.08, 'probability': 0.9932727813720703}, {'word': ' 100', 'start': 85.08, 'end': 85.68, 'probability': 0.8461902737617493}, {'word': ' layers', 'start': 85.68, 'end': 86.18, 'probability': 0.9877716302871704}, {'word': ' tall', 'start': 86.18, 'end': 86.58, 'probability': 0.9958363771438599}, {'word': ' and', 'start': 86.58, 'end': 87.12, 'probability': 0.8137603402137756}, {'word': ' then', 'start': 87.12, 'end': 87.3, 'probability': 0.9908548593521118}]}, {'id': 15, 'seek': 8730, 'start': 87.3, 'end': 92.66, 'text': ' these stacks of cells are copied 40,000 columns across which is then copied', 'tokens': [50364, 613, 30792, 295, 5438, 366, 25365, 3356, 11, 1360, 13766, 2108, 597, 307, 550, 25365, 50636], 'temperature': 0.0, 'avg_logprob': -0.15211981170031488, 'compression_ratio': 1.6926406926406927, 'no_speech_prob': 0.00039202821790240705, 'words': [{'word': ' these', 'start': 87.3, 'end': 87.52, 'probability': 0.11767268925905228}, {'word': ' stacks', 'start': 87.52, 'end': 87.92, 'probability': 0.9843193888664246}, {'word': ' of', 'start': 87.92, 'end': 88.22, 'probability': 0.9917852878570557}, {'word': ' cells', 'start': 88.22, 'end': 88.52, 'probability': 0.9867295026779175}, {'word': ' are', 'start': 88.52, 'end': 88.9, 'probability': 0.9793962240219116}, {'word': ' copied', 'start': 88.9, 'end': 89.28, 'probability': 0.9951398372650146}, {'word': ' 40', 'start': 89.28, 'end': 89.78, 'probability': 0.8634374141693115}, {'word': ',000', 'start': 89.78, 'end': 90.26, 'probability': 0.9611936807632446}, {'word': ' columns', 'start': 90.26, 'end': 90.58, 'probability': 0.9904239773750305}, {'word': ' across', 'start': 90.58, 'end': 91.02, 'probability': 0.9936707019805908}, {'word': ' which', 'start': 91.02, 'end': 91.68, 'probability': 0.27304086089134216}, {'word': ' is', 'start': 91.68, 'end': 91.92, 'probability': 0.9234928488731384}, {'word': ' then', 'start': 91.92, 'end': 92.14, 'probability': 0.9647844433784485}, {'word': ' copied', 'start': 92.14, 'end': 92.66, 'probability': 0.995697021484375}]}, {'id': 16, 'seek': 8730, 'start': 92.66, 'end': 98.88, 'text': ' 50,000 rows down. You can kind of think of it as a 3d Excel spreadsheet where', 'tokens': [50636, 2625, 11, 1360, 13241, 760, 13, 509, 393, 733, 295, 519, 295, 309, 382, 257, 805, 67, 19060, 27733, 689, 50944], 'temperature': 0.0, 'avg_logprob': -0.15211981170031488, 'compression_ratio': 1.6926406926406927, 'no_speech_prob': 0.00039202821790240705, 'words': [{'word': ' 50', 'start': 92.66, 'end': 93.32, 'probability': 0.9616105556488037}, {'word': ',000', 'start': 93.32, 'end': 93.9, 'probability': 0.9933312237262726}, {'word': ' rows', 'start': 93.9, 'end': 94.18, 'probability': 0.9868523478507996}, {'word': ' down.', 'start': 94.18, 'end': 94.58, 'probability': 0.981221616268158}, {'word': ' You', 'start': 95.04, 'end': 95.14, 'probability': 0.9829793572425842}, {'word': ' can', 'start': 95.14, 'end': 95.28, 'probability': 0.9959592223167419}, {'word': ' kind', 'start': 95.28, 'end': 95.52, 'probability': 0.9339910745620728}, {'word': ' of', 'start': 95.52, 'end': 95.68, 'probability': 0.9871577620506287}, {'word': ' think', 'start': 95.68, 'end': 95.88, 'probability': 0.9972090125083923}, {'word': ' of', 'start': 95.88, 'end': 96.08, 'probability': 0.985473096370697}, {'word': ' it', 'start': 96.08, 'end': 96.2, 'probability': 0.9852501749992371}, {'word': ' as', 'start': 96.2, 'end': 96.36, 'probability': 0.9924505352973938}, {'word': ' a', 'start': 96.36, 'end': 96.46, 'probability': 0.9835177659988403}, {'word': ' 3d', 'start': 96.46, 'end': 97.04, 'probability': 0.5933298468589783}, {'word': ' Excel', 'start': 97.04, 'end': 97.58, 'probability': 0.1329524666070938}, {'word': ' spreadsheet', 'start': 97.58, 'end': 98.26, 'probability': 0.9880268573760986}, {'word': ' where', 'start': 98.26, 'end': 98.88, 'probability': 0.5825758576393127}]}, {'id': 17, 'seek': 8730, 'start': 98.88, 'end': 106.34, 'text': ' the values can only be 0 to 7 and this spreadsheet has 40,000 columns by 50,000', 'tokens': [50944, 264, 4190, 393, 787, 312, 1958, 281, 1614, 293, 341, 27733, 575, 3356, 11, 1360, 13766, 538, 2625, 11, 1360, 51319], 'temperature': 0.0, 'avg_logprob': -0.15211981170031488, 'compression_ratio': 1.6926406926406927, 'no_speech_prob': 0.00039202821790240705, 'words': [{'word': ' the', 'start': 98.88, 'end': 99.04, 'probability': 0.99398273229599}, {'word': ' values', 'start': 99.04, 'end': 99.48, 'probability': 0.9942679405212402}, {'word': ' can', 'start': 99.48, 'end': 99.78, 'probability': 0.9926962852478027}, {'word': ' only', 'start': 99.78, 'end': 100.18, 'probability': 0.9915168285369873}, {'word': ' be', 'start': 100.18, 'end': 100.42, 'probability': 0.9976922273635864}, {'word': ' 0', 'start': 100.42, 'end': 100.9, 'probability': 0.8012804985046387}, {'word': ' to', 'start': 100.9, 'end': 101.1, 'probability': 0.8850517272949219}, {'word': ' 7', 'start': 101.1, 'end': 101.48, 'probability': 0.980492115020752}, {'word': ' and', 'start': 101.48, 'end': 102.06, 'probability': 0.4850926399230957}, {'word': ' this', 'start': 102.06, 'end': 102.26, 'probability': 0.9747291803359985}, {'word': ' spreadsheet', 'start': 102.26, 'end': 102.94, 'probability': 0.9961374402046204}, {'word': ' has', 'start': 102.94, 'end': 103.32, 'probability': 0.9912903308868408}, {'word': ' 40', 'start': 103.32, 'end': 103.86, 'probability': 0.9877942800521851}, {'word': ',000', 'start': 103.86, 'end': 104.26, 'probability': 0.9965506494045258}, {'word': ' columns', 'start': 104.26, 'end': 104.78, 'probability': 0.995641827583313}, {'word': ' by', 'start': 104.78, 'end': 105.26, 'probability': 0.9840189218521118}, {'word': ' 50', 'start': 105.26, 'end': 105.82, 'probability': 0.9912529587745667}, {'word': ',000', 'start': 105.82, 'end': 106.34, 'probability': 0.996135026216507}]}, {'id': 18, 'seek': 8730, 'start': 106.34, 'end': 111.92, 'text': ' rows and then there are 100 different spreadsheets stacked in layers one on top', 'tokens': [51319, 13241, 293, 550, 456, 366, 2319, 819, 23651, 1385, 28867, 294, 7914, 472, 322, 1192, 51596], 'temperature': 0.0, 'avg_logprob': -0.15211981170031488, 'compression_ratio': 1.6926406926406927, 'no_speech_prob': 0.00039202821790240705, 'words': [{'word': ' rows', 'start': 106.34, 'end': 106.74, 'probability': 0.9980310797691345}, {'word': ' and', 'start': 106.74, 'end': 107.36, 'probability': 0.6738508343696594}, {'word': ' then', 'start': 107.36, 'end': 107.58, 'probability': 0.9768498539924622}, {'word': ' there', 'start': 107.58, 'end': 107.86, 'probability': 0.9903581738471985}, {'word': ' are', 'start': 107.86, 'end': 107.98, 'probability': 0.9927204847335815}, {'word': ' 100', 'start': 107.98, 'end': 108.7, 'probability': 0.949365496635437}, {'word': ' different', 'start': 108.7, 'end': 109.14, 'probability': 0.9873020648956299}, {'word': ' spreadsheets', 'start': 109.14, 'end': 109.96, 'probability': 0.8697719871997833}, {'word': ' stacked', 'start': 109.96, 'end': 110.3, 'probability': 0.9891515970230103}, {'word': ' in', 'start': 110.3, 'end': 110.54, 'probability': 0.9895658493041992}, {'word': ' layers', 'start': 110.54, 'end': 110.88, 'probability': 0.9563969969749451}, {'word': ' one', 'start': 110.88, 'end': 111.5, 'probability': 0.8367600440979004}, {'word': ' on', 'start': 111.5, 'end': 111.66, 'probability': 0.9851166605949402}, {'word': ' top', 'start': 111.66, 'end': 111.92, 'probability': 0.9960989952087402}]}, {'id': 19, 'seek': 8730, 'start': 111.92, 'end': 117.28, 'text': ' of another. In order to isolate and determine which row and layer to write to', 'tokens': [51596, 295, 1071, 13, 682, 1668, 281, 25660, 293, 6997, 597, 5386, 293, 4583, 281, 2464, 281, 51863], 'temperature': 0.0, 'avg_logprob': -0.15211981170031488, 'compression_ratio': 1.6926406926406927, 'no_speech_prob': 0.00039202821790240705, 'words': [{'word': ' of', 'start': 111.92, 'end': 112.1, 'probability': 0.9926527738571167}, {'word': ' another.', 'start': 112.1, 'end': 112.42, 'probability': 0.997103750705719}, {'word': ' In', 'start': 113.5, 'end': 113.84, 'probability': 0.9710984826087952}, {'word': ' order', 'start': 113.84, 'end': 114.04, 'probability': 0.9997294545173645}, {'word': ' to', 'start': 114.04, 'end': 114.24, 'probability': 0.9993287324905396}, {'word': ' isolate', 'start': 114.24, 'end': 114.62, 'probability': 0.9934773445129395}, {'word': ' and', 'start': 114.62, 'end': 114.9, 'probability': 0.9953086972236633}, {'word': ' determine', 'start': 114.9, 'end': 115.38, 'probability': 0.9969214797019958}, {'word': ' which', 'start': 115.38, 'end': 115.76, 'probability': 0.9953734278678894}, {'word': ' row', 'start': 115.76, 'end': 116.04, 'probability': 0.9887858629226685}, {'word': ' and', 'start': 116.04, 'end': 116.22, 'probability': 0.5065852403640747}, {'word': ' layer', 'start': 116.22, 'end': 116.52, 'probability': 0.980678379535675}, {'word': ' to', 'start': 116.52, 'end': 116.78, 'probability': 0.9937770366668701}, {'word': ' write', 'start': 116.78, 'end': 117.04, 'probability': 0.9857751131057739}, {'word': ' to', 'start': 117.04, 'end': 117.28, 'probability': 0.5703058838844299}]}, {'id': 20, 'seek': 11728, 'start': 117.28, 'end': 122.46, 'text': ' or read from control gate selectors are used along layers and bit line', 'tokens': [50364, 420, 1401, 490, 1969, 8539, 3048, 830, 366, 1143, 2051, 7914, 293, 857, 1622, 50622], 'temperature': 0.0, 'avg_logprob': -0.1526466409365336, 'compression_ratio': 1.668122270742358, 'no_speech_prob': 0.0019875532016158104, 'words': [{'word': ' or', 'start': 117.28, 'end': 117.64, 'probability': 0.4675719439983368}, {'word': ' read', 'start': 117.64, 'end': 117.94, 'probability': 0.959063708782196}, {'word': ' from', 'start': 117.94, 'end': 118.42, 'probability': 0.9868081212043762}, {'word': ' control', 'start': 118.42, 'end': 119.12, 'probability': 0.07240699976682663}, {'word': ' gate', 'start': 119.12, 'end': 119.42, 'probability': 0.8809076547622681}, {'word': ' selectors', 'start': 119.42, 'end': 120.14, 'probability': 0.9397019743919373}, {'word': ' are', 'start': 120.14, 'end': 120.3, 'probability': 0.9608027338981628}, {'word': ' used', 'start': 120.3, 'end': 120.68, 'probability': 0.9949259757995605}, {'word': ' along', 'start': 120.68, 'end': 121.06, 'probability': 0.9362636804580688}, {'word': ' layers', 'start': 121.06, 'end': 121.54, 'probability': 0.9700100421905518}, {'word': ' and', 'start': 121.54, 'end': 121.98, 'probability': 0.9237236380577087}, {'word': ' bit', 'start': 121.98, 'end': 122.18, 'probability': 0.9415079355239868}, {'word': ' line', 'start': 122.18, 'end': 122.46, 'probability': 0.39372488856315613}]}, {'id': 21, 'seek': 11728, 'start': 122.46, 'end': 127.4, 'text': \" selectors are used along the rows. We're going to zoom out to the view that we\", 'tokens': [50622, 3048, 830, 366, 1143, 2051, 264, 13241, 13, 492, 434, 516, 281, 8863, 484, 281, 264, 1910, 300, 321, 50870], 'temperature': 0.0, 'avg_logprob': -0.1526466409365336, 'compression_ratio': 1.668122270742358, 'no_speech_prob': 0.0019875532016158104, 'words': [{'word': ' selectors', 'start': 122.46, 'end': 123.26, 'probability': 0.9930604696273804}, {'word': ' are', 'start': 123.26, 'end': 123.44, 'probability': 0.9947612881660461}, {'word': ' used', 'start': 123.44, 'end': 123.8, 'probability': 0.9950357675552368}, {'word': ' along', 'start': 123.8, 'end': 124.18, 'probability': 0.9978723526000977}, {'word': ' the', 'start': 124.18, 'end': 124.4, 'probability': 0.9915598034858704}, {'word': ' rows.', 'start': 124.4, 'end': 124.74, 'probability': 0.969560444355011}, {'word': \" We're\", 'start': 125.28, 'end': 125.54, 'probability': 0.9420097470283508}, {'word': ' going', 'start': 125.54, 'end': 125.76, 'probability': 0.9970755577087402}, {'word': ' to', 'start': 125.76, 'end': 125.94, 'probability': 0.9767150282859802}, {'word': ' zoom', 'start': 125.94, 'end': 126.16, 'probability': 0.9898808002471924}, {'word': ' out', 'start': 126.16, 'end': 126.48, 'probability': 0.9935193657875061}, {'word': ' to', 'start': 126.48, 'end': 126.68, 'probability': 0.9902229309082031}, {'word': ' the', 'start': 126.68, 'end': 126.82, 'probability': 0.994978129863739}, {'word': ' view', 'start': 126.82, 'end': 127.04, 'probability': 0.9950503706932068}, {'word': ' that', 'start': 127.04, 'end': 127.24, 'probability': 0.9629024863243103}, {'word': ' we', 'start': 127.24, 'end': 127.4, 'probability': 0.9977043271064758}]}, {'id': 22, 'seek': 11728, 'start': 127.4, 'end': 132.64, 'text': \" had earlier where we can see the overall microchip. Here's the 3d array of\", 'tokens': [50870, 632, 3071, 689, 321, 393, 536, 264, 4787, 4532, 339, 647, 13, 1692, 311, 264, 805, 67, 10225, 295, 51126], 'temperature': 0.0, 'avg_logprob': -0.1526466409365336, 'compression_ratio': 1.668122270742358, 'no_speech_prob': 0.0019875532016158104, 'words': [{'word': ' had', 'start': 127.4, 'end': 127.6, 'probability': 0.9949470162391663}, {'word': ' earlier', 'start': 127.6, 'end': 128.06, 'probability': 0.9987415671348572}, {'word': ' where', 'start': 128.06, 'end': 128.44, 'probability': 0.7041330337524414}, {'word': ' we', 'start': 128.44, 'end': 128.64, 'probability': 0.9986888766288757}, {'word': ' can', 'start': 128.64, 'end': 128.8, 'probability': 0.9963478446006775}, {'word': ' see', 'start': 128.8, 'end': 129.14, 'probability': 0.9990552067756653}, {'word': ' the', 'start': 129.14, 'end': 129.36, 'probability': 0.9968035221099854}, {'word': ' overall', 'start': 129.36, 'end': 129.94, 'probability': 0.9914445281028748}, {'word': ' microchip.', 'start': 129.94, 'end': 130.72, 'probability': 0.8942928910255432}, {'word': \" Here's\", 'start': 131.1, 'end': 131.48, 'probability': 0.9637146592140198}, {'word': ' the', 'start': 131.48, 'end': 131.64, 'probability': 0.9920097589492798}, {'word': ' 3d', 'start': 131.64, 'end': 132.08, 'probability': 0.5534548982977867}, {'word': ' array', 'start': 132.08, 'end': 132.38, 'probability': 0.9817609190940857}, {'word': ' of', 'start': 132.38, 'end': 132.64, 'probability': 0.9950352907180786}]}, {'id': 23, 'seek': 11728, 'start': 132.64, 'end': 138.28, 'text': ' charge trap flash cells and control gates that we were just looking at. This is a', 'tokens': [51126, 4602, 11487, 7319, 5438, 293, 1969, 19792, 300, 321, 645, 445, 1237, 412, 13, 639, 307, 257, 51404], 'temperature': 0.0, 'avg_logprob': -0.1526466409365336, 'compression_ratio': 1.668122270742358, 'no_speech_prob': 0.0019875532016158104, 'words': [{'word': ' charge', 'start': 132.64, 'end': 132.9, 'probability': 0.789007306098938}, {'word': ' trap', 'start': 132.9, 'end': 133.3, 'probability': 0.053350165486335754}, {'word': ' flash', 'start': 133.3, 'end': 133.66, 'probability': 0.9466297626495361}, {'word': ' cells', 'start': 133.66, 'end': 134.1, 'probability': 0.9694783091545105}, {'word': ' and', 'start': 134.1, 'end': 134.7, 'probability': 0.9474236965179443}, {'word': ' control', 'start': 134.7, 'end': 135.16, 'probability': 0.9799624681472778}, {'word': ' gates', 'start': 135.16, 'end': 135.52, 'probability': 0.9710557460784912}, {'word': ' that', 'start': 135.52, 'end': 135.76, 'probability': 0.9846603274345398}, {'word': ' we', 'start': 135.76, 'end': 135.92, 'probability': 0.9979296922683716}, {'word': ' were', 'start': 135.92, 'end': 136.02, 'probability': 0.9856207966804504}, {'word': ' just', 'start': 136.02, 'end': 136.22, 'probability': 0.9892106056213379}, {'word': ' looking', 'start': 136.22, 'end': 136.6, 'probability': 0.9990034699440002}, {'word': ' at.', 'start': 136.6, 'end': 136.86, 'probability': 0.9984827637672424}, {'word': ' This', 'start': 137.58, 'end': 137.78, 'probability': 0.9893791079521179}, {'word': ' is', 'start': 137.78, 'end': 138.12, 'probability': 0.9933172464370728}, {'word': ' a', 'start': 138.12, 'end': 138.28, 'probability': 0.9958898425102234}]}, {'id': 24, 'seek': 11728, 'start': 138.28, 'end': 144.18, 'text': \" massive layout of memory cells but engineers didn't stop there. In order to\", 'tokens': [51404, 5994, 13333, 295, 4675, 5438, 457, 11955, 994, 380, 1590, 456, 13, 682, 1668, 281, 51708], 'temperature': 0.0, 'avg_logprob': -0.1526466409365336, 'compression_ratio': 1.668122270742358, 'no_speech_prob': 0.0019875532016158104, 'words': [{'word': ' massive', 'start': 138.28, 'end': 138.76, 'probability': 0.9959795475006104}, {'word': ' layout', 'start': 138.76, 'end': 139.18, 'probability': 0.9772334098815918}, {'word': ' of', 'start': 139.18, 'end': 139.52, 'probability': 0.9945259094238281}, {'word': ' memory', 'start': 139.52, 'end': 139.78, 'probability': 0.9967619180679321}, {'word': ' cells', 'start': 139.78, 'end': 140.26, 'probability': 0.9926179051399231}, {'word': ' but', 'start': 140.26, 'end': 140.74, 'probability': 0.4952060878276825}, {'word': ' engineers', 'start': 140.74, 'end': 141.82, 'probability': 0.9345711469650269}, {'word': \" didn't\", 'start': 141.82, 'end': 142.42, 'probability': 0.9956623017787933}, {'word': ' stop', 'start': 142.42, 'end': 142.76, 'probability': 0.9947478175163269}, {'word': ' there.', 'start': 142.76, 'end': 143.18, 'probability': 0.9919530749320984}, {'word': ' In', 'start': 143.72, 'end': 143.82, 'probability': 0.9875791668891907}, {'word': ' order', 'start': 143.82, 'end': 144.02, 'probability': 0.9997376799583435}, {'word': ' to', 'start': 144.02, 'end': 144.18, 'probability': 0.9995772242546082}]}, {'id': 25, 'seek': 14418, 'start': 144.18, 'end': 149.9, 'text': ' fit more capacity they copied this layout onto the other side and then copied it', 'tokens': [50364, 3318, 544, 6042, 436, 25365, 341, 13333, 3911, 264, 661, 1252, 293, 550, 25365, 309, 50648], 'temperature': 0.0, 'avg_logprob': -0.1756504105358589, 'compression_ratio': 1.565217391304348, 'no_speech_prob': 0.00769414845854044, 'words': [{'word': ' fit', 'start': 144.18, 'end': 144.38, 'probability': 0.26736798882484436}, {'word': ' more', 'start': 144.38, 'end': 144.64, 'probability': 0.9877270460128784}, {'word': ' capacity', 'start': 144.64, 'end': 145.2, 'probability': 0.9984055161476135}, {'word': ' they', 'start': 145.2, 'end': 145.9, 'probability': 0.10886938124895096}, {'word': ' copied', 'start': 145.9, 'end': 146.32, 'probability': 0.9949004054069519}, {'word': ' this', 'start': 146.32, 'end': 146.64, 'probability': 0.9748058319091797}, {'word': ' layout', 'start': 146.64, 'end': 147.0, 'probability': 0.9948033690452576}, {'word': ' onto', 'start': 147.0, 'end': 147.38, 'probability': 0.934031069278717}, {'word': ' the', 'start': 147.38, 'end': 147.6, 'probability': 0.9929311275482178}, {'word': ' other', 'start': 147.6, 'end': 147.9, 'probability': 0.9855747222900391}, {'word': ' side', 'start': 147.9, 'end': 148.4, 'probability': 0.9974426031112671}, {'word': ' and', 'start': 148.4, 'end': 148.94, 'probability': 0.820522665977478}, {'word': ' then', 'start': 148.94, 'end': 149.14, 'probability': 0.979292631149292}, {'word': ' copied', 'start': 149.14, 'end': 149.62, 'probability': 0.9915918111801147}, {'word': ' it', 'start': 149.62, 'end': 149.9, 'probability': 0.995486319065094}]}, {'id': 26, 'seek': 14418, 'start': 149.9, 'end': 155.82, 'text': \" eight times again and crammed it all into a single microchip and that's it. Three\", 'tokens': [50648, 3180, 1413, 797, 293, 941, 19859, 309, 439, 666, 257, 2167, 4532, 339, 647, 293, 300, 311, 309, 13, 6244, 50946], 'temperature': 0.0, 'avg_logprob': -0.1756504105358589, 'compression_ratio': 1.565217391304348, 'no_speech_prob': 0.00769414845854044, 'words': [{'word': ' eight', 'start': 149.9, 'end': 150.32, 'probability': 0.6952394247055054}, {'word': ' times', 'start': 150.32, 'end': 150.74, 'probability': 0.9968165755271912}, {'word': ' again', 'start': 150.74, 'end': 151.32, 'probability': 0.9869785308837891}, {'word': ' and', 'start': 151.32, 'end': 151.88, 'probability': 0.8257471919059753}, {'word': ' crammed', 'start': 151.88, 'end': 152.32, 'probability': 0.9276864230632782}, {'word': ' it', 'start': 152.32, 'end': 152.48, 'probability': 0.9829204678535461}, {'word': ' all', 'start': 152.48, 'end': 152.66, 'probability': 0.9937530159950256}, {'word': ' into', 'start': 152.66, 'end': 152.96, 'probability': 0.9899217486381531}, {'word': ' a', 'start': 152.96, 'end': 153.14, 'probability': 0.9950297474861145}, {'word': ' single', 'start': 153.14, 'end': 153.54, 'probability': 0.9969063401222229}, {'word': ' microchip', 'start': 153.54, 'end': 154.28, 'probability': 0.9320282141367594}, {'word': ' and', 'start': 154.28, 'end': 154.76, 'probability': 0.4187902510166168}, {'word': \" that's\", 'start': 154.76, 'end': 155.02, 'probability': 0.9826403260231018}, {'word': ' it.', 'start': 155.02, 'end': 155.22, 'probability': 0.9987896084785461}, {'word': ' Three', 'start': 155.6, 'end': 155.82, 'probability': 0.7381978034973145}]}, {'id': 27, 'seek': 14418, 'start': 155.82, 'end': 162.18, 'text': ' weeks of non-stop binging movies and TV squeezed into a microchip the size of a', 'tokens': [50946, 3259, 295, 2107, 12, 13559, 272, 8716, 6233, 293, 3558, 39470, 666, 257, 4532, 339, 647, 264, 2744, 295, 257, 51260], 'temperature': 0.0, 'avg_logprob': -0.1756504105358589, 'compression_ratio': 1.565217391304348, 'no_speech_prob': 0.00769414845854044, 'words': [{'word': ' weeks', 'start': 155.82, 'end': 156.26, 'probability': 0.9967184662818909}, {'word': ' of', 'start': 156.26, 'end': 156.5, 'probability': 0.9952428936958313}, {'word': ' non', 'start': 156.5, 'end': 156.84, 'probability': 0.9875624179840088}, {'word': '-stop', 'start': 156.84, 'end': 157.28, 'probability': 0.8174833357334137}, {'word': ' binging', 'start': 157.28, 'end': 157.8, 'probability': 0.8136276602745056}, {'word': ' movies', 'start': 157.8, 'end': 158.32, 'probability': 0.9932845830917358}, {'word': ' and', 'start': 158.32, 'end': 158.62, 'probability': 0.7760738730430603}, {'word': ' TV', 'start': 158.62, 'end': 159.08, 'probability': 0.7761942744255066}, {'word': ' squeezed', 'start': 159.08, 'end': 159.82, 'probability': 0.9283608198165894}, {'word': ' into', 'start': 159.82, 'end': 160.3, 'probability': 0.9932931661605835}, {'word': ' a', 'start': 160.3, 'end': 160.48, 'probability': 0.9961671233177185}, {'word': ' microchip', 'start': 160.48, 'end': 161.2, 'probability': 0.9969260096549988}, {'word': ' the', 'start': 161.2, 'end': 161.42, 'probability': 0.9699200987815857}, {'word': ' size', 'start': 161.42, 'end': 161.78, 'probability': 0.9977115392684937}, {'word': ' of', 'start': 161.78, 'end': 162.04, 'probability': 0.9980254173278809}, {'word': ' a', 'start': 162.04, 'end': 162.18, 'probability': 0.9984627962112427}]}, {'id': 28, 'seek': 14418, 'start': 162.18, 'end': 167.9, 'text': ' dime. Watch our follow up episode to get a complete and in-depth understanding as', 'tokens': [51260, 36330, 13, 7277, 527, 1524, 493, 3500, 281, 483, 257, 3566, 293, 294, 12, 25478, 3701, 382, 51540], 'temperature': 0.0, 'avg_logprob': -0.1756504105358589, 'compression_ratio': 1.565217391304348, 'no_speech_prob': 0.00769414845854044, 'words': [{'word': ' dime.', 'start': 162.18, 'end': 162.5, 'probability': 0.9970245957374573}, {'word': ' Watch', 'start': 163.1, 'end': 163.4, 'probability': 0.9657991528511047}, {'word': ' our', 'start': 163.4, 'end': 163.6, 'probability': 0.9863876104354858}, {'word': ' follow', 'start': 163.6, 'end': 163.94, 'probability': 0.9714640974998474}, {'word': ' up', 'start': 163.94, 'end': 164.18, 'probability': 0.45669710636138916}, {'word': ' episode', 'start': 164.18, 'end': 164.58, 'probability': 0.9823446273803711}, {'word': ' to', 'start': 164.58, 'end': 164.88, 'probability': 0.9868199229240417}, {'word': ' get', 'start': 164.88, 'end': 165.04, 'probability': 0.9985815286636353}, {'word': ' a', 'start': 165.04, 'end': 165.16, 'probability': 0.9970627427101135}, {'word': ' complete', 'start': 165.16, 'end': 165.58, 'probability': 0.9968557357788086}, {'word': ' and', 'start': 165.58, 'end': 166.04, 'probability': 0.9759830832481384}, {'word': ' in', 'start': 166.04, 'end': 166.32, 'probability': 0.9942409992218018}, {'word': '-depth', 'start': 166.32, 'end': 166.58, 'probability': 0.8872741758823395}, {'word': ' understanding', 'start': 166.58, 'end': 167.46, 'probability': 0.9969574213027954}, {'word': ' as', 'start': 167.46, 'end': 167.9, 'probability': 0.9884383082389832}]}, {'id': 29, 'seek': 16790, 'start': 167.9, 'end': 171.86, 'text': ' to how everything that I just talked about works. Thanks.', 'tokens': [50364, 281, 577, 1203, 300, 286, 445, 2825, 466, 1985, 13, 2561, 13, 50634], 'temperature': 0.0, 'avg_logprob': -0.34203971227010094, 'compression_ratio': 0.9047619047619048, 'no_speech_prob': 0.03672752529382706, 'words': [{'word': ' to', 'start': 167.9, 'end': 168.08, 'probability': 0.5734859704971313}, {'word': ' how', 'start': 168.08, 'end': 168.3, 'probability': 0.9772413969039917}, {'word': ' everything', 'start': 168.3, 'end': 168.9, 'probability': 0.9573777318000793}, {'word': ' that', 'start': 168.9, 'end': 169.24, 'probability': 0.804620087146759}, {'word': ' I', 'start': 169.24, 'end': 169.36, 'probability': 0.9872561693191528}, {'word': ' just', 'start': 169.36, 'end': 169.58, 'probability': 0.9832421541213989}, {'word': ' talked', 'start': 169.58, 'end': 169.9, 'probability': 0.9957744479179382}, {'word': ' about', 'start': 169.9, 'end': 170.26, 'probability': 0.9986869692802429}, {'word': ' works.', 'start': 170.26, 'end': 170.72, 'probability': 0.992649495601654}, {'word': ' Thanks.', 'start': 171.44, 'end': 171.86, 'probability': 0.9921392798423767}]}], 'language': 'en'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the transcription segments\n",
        "segments = result['segments']\n",
        "\n",
        "# Prepare lists to hold sentences and their timestamps\n",
        "sentence_texts = []\n",
        "sentence_times = []\n",
        "\n",
        "current_sentence = ''\n",
        "current_start = None\n",
        "\n",
        "# Regular expression to detect sentence-ending punctuation\n",
        "sentence_endings = re.compile(r'[.!?]')\n",
        "\n",
        "for segment in segments:\n",
        "    words = segment['words']\n",
        "    for word_info in words:\n",
        "        word = word_info['word']\n",
        "        word_start = word_info['start']\n",
        "        word_end = word_info['end']\n",
        "\n",
        "        if current_start is None:\n",
        "            current_start = word_start\n",
        "\n",
        "        current_sentence += word\n",
        "\n",
        "        if sentence_endings.search(word):\n",
        "            # End of sentence detected\n",
        "            current_end = word_end\n",
        "            sentence_texts.append(current_sentence.strip())\n",
        "            sentence_times.append((current_start, current_end, current_sentence.strip()))\n",
        "            # Reset for next sentence\n",
        "            current_sentence = ''\n",
        "            current_start = None\n",
        "        else:\n",
        "            current_sentence += ' '\n",
        "\n",
        "# Handle any remaining sentence\n",
        "if current_sentence:\n",
        "    current_end = word_end\n",
        "    sentence_texts.append(current_sentence.strip())\n",
        "    sentence_times.append((current_start, current_end, current_sentence.strip()))"
      ],
      "metadata": {
        "id": "nKn908mw2gS1"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0H234DE3PiP",
        "outputId": "58f35e37-dafc-4835-9b92-162ac0298b0f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Most  smartphones  can  store  128GB  and  this  solid -state  drive  can  store  one  terabyte  of  data  and  it  all  happens  inside  this  microchip  right  here.', 'If  this  one  terabyte  solid -state  drive  were  full  of  movies  and  TV  shows  it  would  take  about  three  weeks  of  non -stop  binging  to  watch  them  all.', 'So  how  can  this  incredibly  small  microchip  fit  such  an  insane  amount  of  content?', \"To  understand  that  we've  got  to  zoom  into  a  nanoscopic  view  of  the  insides.\", 'In  here  we  can  see  an  individual  memory  cell  called  charge  trap  flash.', 'This  memory  cell  stores  three  bits  of  information  by  trapping  different  levels  of  electrons  on  a  charge  trap.', 'Very  few  extra  electrons  are  a  1  1  1  while  a  lot  of  electrons  are  a  0  0  0  and  the  other  levels  of  trapped  electrons  have  other  three  bit  designations.', \"Measuring  this  value  doesn't  change  the  amount  of  electrons  and  once  electrons  are  placed  on  the  charge  trap  they  stay  trapped  there  for  years.\", 'However  when  the  memory  cell  is  erased  the  electrons  are  forcibly  removed.', \"To  reach  a  terabyte  of  storage  capacity  in  a  single  chip  this  memory  cell  is  copied  and  it's  copied  a  lot.\", 'First  these  memory  cells  are  stacked  100  layers  tall  and  then  these  stacks  of  cells  are  copied  40 ,000  columns  across  which  is  then  copied  50 ,000  rows  down.', 'You  can  kind  of  think  of  it  as  a  3d  Excel  spreadsheet  where  the  values  can  only  be  0  to  7  and  this  spreadsheet  has  40 ,000  columns  by  50 ,000  rows  and  then  there  are  100  different  spreadsheets  stacked  in  layers  one  on  top  of  another.', 'In  order  to  isolate  and  determine  which  row  and  layer  to  write  to  or  read  from  control  gate  selectors  are  used  along  layers  and  bit  line  selectors  are  used  along  the  rows.', \"We're  going  to  zoom  out  to  the  view  that  we  had  earlier  where  we  can  see  the  overall  microchip.\", \"Here's  the  3d  array  of  charge  trap  flash  cells  and  control  gates  that  we  were  just  looking  at.\", \"This  is  a  massive  layout  of  memory  cells  but  engineers  didn't  stop  there.\", \"In  order  to  fit  more  capacity  they  copied  this  layout  onto  the  other  side  and  then  copied  it  eight  times  again  and  crammed  it  all  into  a  single  microchip  and  that's  it.\", 'Three  weeks  of  non -stop  binging  movies  and  TV  squeezed  into  a  microchip  the  size  of  a  dime.', 'Watch  our  follow  up  episode  to  get  a  complete  and  in -depth  understanding  as  to  how  everything  that  I  just  talked  about  works.', 'Thanks.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_times)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XnuR8yl3Ugx",
        "outputId": "0a54d4bd-4cec-4539-f027-38e772a2e03f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0.0, 12.6, 'Most  smartphones  can  store  128GB  and  this  solid -state  drive  can  store  one  terabyte  of  data  and  it  all  happens  inside  this  microchip  right  here.'), (12.9, 22.1, 'If  this  one  terabyte  solid -state  drive  were  full  of  movies  and  TV  shows  it  would  take  about  three  weeks  of  non -stop  binging  to  watch  them  all.'), (22.46, 28.12, 'So  how  can  this  incredibly  small  microchip  fit  such  an  insane  amount  of  content?'), (28.56, 33.24, \"To  understand  that  we've  got  to  zoom  into  a  nanoscopic  view  of  the  insides.\"), (33.88, 39.08, 'In  here  we  can  see  an  individual  memory  cell  called  charge  trap  flash.'), (39.6, 45.56, 'This  memory  cell  stores  three  bits  of  information  by  trapping  different  levels  of  electrons  on  a  charge  trap.'), (45.9, 58.34, 'Very  few  extra  electrons  are  a  1  1  1  while  a  lot  of  electrons  are  a  0  0  0  and  the  other  levels  of  trapped  electrons  have  other  three  bit  designations.'), (58.34, 68.12, \"Measuring  this  value  doesn't  change  the  amount  of  electrons  and  once  electrons  are  placed  on  the  charge  trap  they  stay  trapped  there  for  years.\"), (68.62, 73.5, 'However  when  the  memory  cell  is  erased  the  electrons  are  forcibly  removed.'), (74.02, 82.4, \"To  reach  a  terabyte  of  storage  capacity  in  a  single  chip  this  memory  cell  is  copied  and  it's  copied  a  lot.\"), (82.88, 94.58, 'First  these  memory  cells  are  stacked  100  layers  tall  and  then  these  stacks  of  cells  are  copied  40 ,000  columns  across  which  is  then  copied  50 ,000  rows  down.'), (95.04, 112.42, 'You  can  kind  of  think  of  it  as  a  3d  Excel  spreadsheet  where  the  values  can  only  be  0  to  7  and  this  spreadsheet  has  40 ,000  columns  by  50 ,000  rows  and  then  there  are  100  different  spreadsheets  stacked  in  layers  one  on  top  of  another.'), (113.5, 124.74, 'In  order  to  isolate  and  determine  which  row  and  layer  to  write  to  or  read  from  control  gate  selectors  are  used  along  layers  and  bit  line  selectors  are  used  along  the  rows.'), (125.28, 130.72, \"We're  going  to  zoom  out  to  the  view  that  we  had  earlier  where  we  can  see  the  overall  microchip.\"), (131.1, 136.86, \"Here's  the  3d  array  of  charge  trap  flash  cells  and  control  gates  that  we  were  just  looking  at.\"), (137.58, 143.18, \"This  is  a  massive  layout  of  memory  cells  but  engineers  didn't  stop  there.\"), (143.72, 155.22, \"In  order  to  fit  more  capacity  they  copied  this  layout  onto  the  other  side  and  then  copied  it  eight  times  again  and  crammed  it  all  into  a  single  microchip  and  that's  it.\"), (155.6, 162.5, 'Three  weeks  of  non -stop  binging  movies  and  TV  squeezed  into  a  microchip  the  size  of  a  dime.'), (163.1, 170.72, 'Watch  our  follow  up  episode  to  get  a  complete  and  in -depth  understanding  as  to  how  everything  that  I  just  talked  about  works.'), (171.44, 171.86, 'Thanks.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "technical_keywords = {\n",
        "    'gpu_computing': [\n",
        "        'gpu', 'cuda', 'parallel computing', 'graphics processing', 'shader',\n",
        "        'compute shader', 'opencl', 'vulkan', 'graphics pipeline', 'rendering',\n",
        "        'texture', 'buffer', 'compute unit', 'thread block', 'warp', 'kernel'\n",
        "    ],\n",
        "    'computer_architecture': [\n",
        "        'instruction set', 'isa', 'pipeline', 'branch prediction', 'cache hierarchy',\n",
        "        'memory hierarchy', 'von neumann', 'harvard architecture', 'superscalar',\n",
        "        'out of order execution', 'speculative execution', 'microarchitecture',\n",
        "        'fetch', 'decode', 'execute', 'writeback', 'forwarding', 'hazard',\n",
        "        'stall', 'microcode', 'microinstruction'\n",
        "    ],\n",
        "    'assembly_programming': [\n",
        "        'assembly', 'assembler', 'mnemonic', 'opcode', 'operand', 'risc',\n",
        "        'cisc', 'arm assembly', 'x86 assembly', 'riscv', 'risc-v', 'instruction set',\n",
        "        'register file', 'immediate value', 'addressing mode', 'branch instruction',\n",
        "        'jump instruction', 'load store', 'arithmetic instruction', 'logical instruction'\n",
        "    ],\n",
        "    'low_level': [\n",
        "        'memory', 'pointer', 'address', 'register', 'cache', 'assembly',\n",
        "        'instruction', 'binary', 'bit', 'byte', 'stack', 'heap', 'allocation',\n",
        "        'memory mapping', 'virtual memory', 'physical memory', 'page table',\n",
        "        'segmentation', 'protection ring', 'privilege level'\n",
        "    ],\n",
        "    'system_programming': [\n",
        "        'operating system', 'driver', 'interrupt', 'system call', 'process',\n",
        "        'thread', 'scheduling', 'synchronization', 'mutex', 'semaphore',\n",
        "        'context switch', 'privilege level', 'kernel mode', 'user mode'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Flatten the list of keywords\n",
        "all_keywords = set()\n",
        "for keywords in technical_keywords.values():\n",
        "    all_keywords.update(keywords)"
      ],
      "metadata": {
        "id": "HuBC1yNi3XyR"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_contains_keyword(sentence, keywords):\n",
        "    sentence_lower = sentence.lower()\n",
        "    for keyword in keywords:\n",
        "        if re.search(r'\\b' + re.escape(keyword.lower()) + r'\\b', sentence_lower):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# Identify technical sentences\n",
        "technical_sentences = []\n",
        "for start, end, sentence in sentence_times:\n",
        "    if sentence_contains_keyword(sentence, all_keywords):\n",
        "        technical_sentences.append((start, end, sentence))\n",
        "\n",
        "print(\"Technical sentences identified:\")\n",
        "for s in technical_sentences:\n",
        "    print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxrDI_JK3Zna",
        "outputId": "67257eec-ef7f-4a08-a6a5-41e3a4f312a5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Technical sentences identified:\n",
            "(33.88, 39.08, 'In  here  we  can  see  an  individual  memory  cell  called  charge  trap  flash.')\n",
            "(39.6, 45.56, 'This  memory  cell  stores  three  bits  of  information  by  trapping  different  levels  of  electrons  on  a  charge  trap.')\n",
            "(45.9, 58.34, 'Very  few  extra  electrons  are  a  1  1  1  while  a  lot  of  electrons  are  a  0  0  0  and  the  other  levels  of  trapped  electrons  have  other  three  bit  designations.')\n",
            "(68.62, 73.5, 'However  when  the  memory  cell  is  erased  the  electrons  are  forcibly  removed.')\n",
            "(74.02, 82.4, \"To  reach  a  terabyte  of  storage  capacity  in  a  single  chip  this  memory  cell  is  copied  and  it's  copied  a  lot.\")\n",
            "(82.88, 94.58, 'First  these  memory  cells  are  stacked  100  layers  tall  and  then  these  stacks  of  cells  are  copied  40 ,000  columns  across  which  is  then  copied  50 ,000  rows  down.')\n",
            "(113.5, 124.74, 'In  order  to  isolate  and  determine  which  row  and  layer  to  write  to  or  read  from  control  gate  selectors  are  used  along  layers  and  bit  line  selectors  are  used  along  the  rows.')\n",
            "(137.58, 143.18, \"This  is  a  massive  layout  of  memory  cells  but  engineers  didn't  stop  there.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define minimum and maximum clip durations\n",
        "min_clip_duration = 30  # Minimum 30 seconds\n",
        "max_clip_duration = 75  # Maximum 75 seconds\n",
        "\n",
        "clips = []\n",
        "current_clip_sentences = []\n",
        "current_clip_start = None\n",
        "current_clip_end = None\n",
        "\n",
        "idx = 0\n",
        "sentence_count = len(sentence_times)\n",
        "\n",
        "while idx < sentence_count:\n",
        "    start, end, sentence = sentence_times[idx]\n",
        "    is_technical = sentence_contains_keyword(sentence, all_keywords)\n",
        "\n",
        "    if is_technical:\n",
        "        # Start new clip\n",
        "        current_clip_start = start\n",
        "        current_clip_end = end\n",
        "        current_clip_sentences.append((start, end, sentence))\n",
        "\n",
        "        # Expand clip to meet minimum duration\n",
        "        clip_duration = current_clip_end - current_clip_start\n",
        "        idx += 1\n",
        "        while clip_duration < min_clip_duration and idx < sentence_count:\n",
        "            next_start, next_end, next_sentence = sentence_times[idx]\n",
        "            current_clip_end = next_end\n",
        "            current_clip_sentences.append((next_start, next_end, next_sentence))\n",
        "            clip_duration = current_clip_end - current_clip_start\n",
        "            idx += 1\n",
        "\n",
        "        # Trim clip if it exceeds maximum duration\n",
        "        if clip_duration > max_clip_duration:\n",
        "            current_clip_end = current_clip_start + max_clip_duration\n",
        "            clip_duration = max_clip_duration\n",
        "            # Remove sentences that exceed the maximum duration\n",
        "            adjusted_sentences = []\n",
        "            for s_start, s_end, s_sentence in current_clip_sentences:\n",
        "                if s_end <= current_clip_end:\n",
        "                    adjusted_sentences.append((s_start, s_end, s_sentence))\n",
        "                else:\n",
        "                    break\n",
        "            current_clip_sentences = adjusted_sentences\n",
        "\n",
        "        # Save the clip\n",
        "        clips.append((current_clip_start, current_clip_end, current_clip_sentences.copy()))\n",
        "\n",
        "        # Reset for next clip\n",
        "        current_clip_sentences = []\n",
        "        current_clip_start = None\n",
        "        current_clip_end = None\n",
        "    else:\n",
        "        idx += 1  # Move to the next sentence\n",
        "\n",
        "print(\"Clips to be extracted:\")\n",
        "for idx, (start_time, end_time, sentences_in_clip) in enumerate(clips):\n",
        "    duration = end_time - start_time\n",
        "    print(f\"\\nClip {idx+1}: Start - {start_time:.2f}s, End - {end_time:.2f}s, Duration - {duration:.2f}s\")\n",
        "    print(\"Sentences in clip:\")\n",
        "    for s in sentences_in_clip:\n",
        "        print(f\" - {s[2]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N8vk9gA3b2h",
        "outputId": "0a6178ad-ea85-467e-99d4-3e248ffaceac"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clips to be extracted:\n",
            "\n",
            "Clip 1: Start - 33.88s, End - 68.12s, Duration - 34.24s\n",
            "Sentences in clip:\n",
            " - In  here  we  can  see  an  individual  memory  cell  called  charge  trap  flash.\n",
            " - This  memory  cell  stores  three  bits  of  information  by  trapping  different  levels  of  electrons  on  a  charge  trap.\n",
            " - Very  few  extra  electrons  are  a  1  1  1  while  a  lot  of  electrons  are  a  0  0  0  and  the  other  levels  of  trapped  electrons  have  other  three  bit  designations.\n",
            " - Measuring  this  value  doesn't  change  the  amount  of  electrons  and  once  electrons  are  placed  on  the  charge  trap  they  stay  trapped  there  for  years.\n",
            "\n",
            "Clip 2: Start - 68.62s, End - 112.42s, Duration - 43.80s\n",
            "Sentences in clip:\n",
            " - However  when  the  memory  cell  is  erased  the  electrons  are  forcibly  removed.\n",
            " - To  reach  a  terabyte  of  storage  capacity  in  a  single  chip  this  memory  cell  is  copied  and  it's  copied  a  lot.\n",
            " - First  these  memory  cells  are  stacked  100  layers  tall  and  then  these  stacks  of  cells  are  copied  40 ,000  columns  across  which  is  then  copied  50 ,000  rows  down.\n",
            " - You  can  kind  of  think  of  it  as  a  3d  Excel  spreadsheet  where  the  values  can  only  be  0  to  7  and  this  spreadsheet  has  40 ,000  columns  by  50 ,000  rows  and  then  there  are  100  different  spreadsheets  stacked  in  layers  one  on  top  of  another.\n",
            "\n",
            "Clip 3: Start - 113.50s, End - 155.22s, Duration - 41.72s\n",
            "Sentences in clip:\n",
            " - In  order  to  isolate  and  determine  which  row  and  layer  to  write  to  or  read  from  control  gate  selectors  are  used  along  layers  and  bit  line  selectors  are  used  along  the  rows.\n",
            " - We're  going  to  zoom  out  to  the  view  that  we  had  earlier  where  we  can  see  the  overall  microchip.\n",
            " - Here's  the  3d  array  of  charge  trap  flash  cells  and  control  gates  that  we  were  just  looking  at.\n",
            " - This  is  a  massive  layout  of  memory  cells  but  engineers  didn't  stop  there.\n",
            " - In  order  to  fit  more  capacity  they  copied  this  layout  onto  the  other  side  and  then  copied  it  eight  times  again  and  crammed  it  all  into  a  single  microchip  and  that's  it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(video_filename):\n",
        "    print(f\"Video file {video_filename} not found.\")\n",
        "else:\n",
        "    os.makedirs('clips', exist_ok=True)\n",
        "    clip_filenames = []\n",
        "    for idx, (start, end, _) in enumerate(clips):\n",
        "        output_path = f'clips/clip_{idx+1}.mp4'\n",
        "        command = [\n",
        "            'ffmpeg',\n",
        "            '-y',\n",
        "            '-i', video_filename,\n",
        "            '-ss', str(start),\n",
        "            '-to', str(end),\n",
        "            '-c', 'copy',\n",
        "            output_path\n",
        "        ]\n",
        "        subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
        "        clip_filenames.append(output_path)\n",
        "    print(\"Video clips extracted:\")\n",
        "    for fname in clip_filenames:\n",
        "        print(fname)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5LAphFj3hUv",
        "outputId": "db9cc988-0475-4677-d613-47b0c4085c3a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video clips extracted:\n",
            "clips/clip_1.mp4\n",
            "clips/clip_2.mp4\n",
            "clips/clip_3.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for fname in clip_filenames:\n",
        "    print(f\"\\nDisplaying {fname}:\")\n",
        "    # display(Video(fname, embed=True))\n",
        "    # Uncomment the following line if you wish to download the clips\n",
        "    files.download(fname)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "XYVP20UL3laL",
        "outputId": "5e8850be-bc4e-4c05-d079-0786be13abf7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Displaying clips/clip_1.mp4:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1159f4af-a386-426e-b265-334e7e4c417e\", \"clip_1.mp4\", 3617323)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Displaying clips/clip_2.mp4:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_58284e97-e184-4dbc-a518-9eb5688acf74\", \"clip_2.mp4\", 16641522)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Displaying clips/clip_3.mp4:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8b0f27cf-db51-4ffe-baf0-1e90c9a05cce\", \"clip_3.mp4\", 9971685)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s_TUTTxs3q2D"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}